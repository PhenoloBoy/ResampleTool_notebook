---
title: "Resample Tool With R"
output: html_notebook
---

# Reading in and preparing data 

When running the notebooks on VITOâ€™s servers, the user can follow the directions shown in 
https://nbviewer.jupyter.org/github/VITObelgium/notebook-samples/raw/master/datasets/probav/Reading%20PROBA-V%20using%20R.ipynb to find locations of PROBA-V products. Doing so, the data set (netCDF files) will be located and available in the VITO's servers.

Alternatively, when working locally, the R-user can choose to automatically download Copernicus land data (https://land.copernicus.eu/global/) using the functions found in https://github.com/cgls/Copernicus-Global-Land-Service-Data-Download-with-R. 

Once the data set is available, *raster* package functionality is used to prepare it for resampling. 

```{r}
library(raster)
library(knitr)
#setwd("/Users/xavi_rp/Documents/D6_LPD/ResampleTool_notebook")


# ndvi_files is a list of the available files (netCFD or Raster* objects)
ndvi_files <- list(paste0("/Users/xavi_rp/Documents/D6_LPD/NDVI_resample", "/ndvi300m_Cat.tif"))
r <- raster(ndvi_files[[1]])

```


The original netCDF file might contain flagged data corresponding to NoData (NA), etc, which needs to be dealt with. In the following table it can be seen the range of valid values, both DN and physical, for each product and data layer.

```{r echo = FALSE}
cutoff_method_df <- read.csv("Table_cutoff_and_resampleMethod.csv",
                             stringsAsFactors = FALSE,
                             header = TRUE)
cutoff_method_df <- as.data.frame(gsub("(\\[|\\])", "", as.matrix(cutoff_method_df)))
cutoff_method_df <- as.data.frame(gsub("(\\.\\.\\.)", "_", as.matrix(cutoff_method_df)))

cutoff_method_df$Valid.range.DN.from <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), "_"))[[1]]))
cutoff_method_df$Valid.range.DN.to <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), "_"))[[2]]))

cutoff_method_df$Valid.range.physical.from <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), "_"))[[1]]))
cutoff_method_df$Valid.range.physical.to <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), "_"))[[2]]))

cutoff_method_df <- cutoff_method_df[, c("Product","Data.layer.in.file",
                                         "Valid.range.DN.from", "Valid.range.DN.to",
                                         "Valid.range.physical.from", "Valid.range.physical.to",
                                         "Resample.method", "Additional.cutoff")]

#print(cutoff_method_df)
kable(cutoff_method_df[, 1:6], caption = "")

cutoff_method_df_ndvi_to <- cutoff_method_df[cutoff_method_df$Data.layer.in.file == "NDVI", c(4, 6)]
```
```{r}

```


In case of the NDVI products and netCDF files, assigned values > `r as.character(cutoff_method_df_ndvi_to[1])` are flagged and need to be converted into NA. When netCDF files are read in as a *Raster*\* object and values transformed into real NDVI values, the cuttoff for flagged cells is `r as.character(cutoff_method_df_ndvi_to[2])`. Therefore, all cells > `r as.character(cutoff_method_df_ndvi_to[2])` have to be set to NA.



```{r}
if(grepl("ndvi", ndvi_files[[1]], ignore.case = TRUE)){
  cuttoff_flag <- as.numeric(cutoff_method_df_ndvi_to[2])
}else{
  stop("Please define 'cuttoff_flag' (cuttoff value for flagged cells) for the Raster* object")
}

r[r > cuttoff_flag] <- NA

```



# Resampling using the aggregation approach

There are several approaches to resample data to a coarser resolution. The area-based aggregation methods are based in grouping rectangular areas of cells of the finer resolution image to create a new map with larger cells. To do that, the function *aggregate()* of the package *raster* needs to know the factor of aggregation. In this case, the factor is 3 as it needs to go from 333m to 1km. In addition, *aggregate()* can perform the calculation using different functions. While the default is the average (*mean()*) it can work also with *modal()*, *max()* or *min()*.

As for the pixel coordinate definition for both the 300m and the 1km products, no proper aggregation of the finer resolution product can be performed at the minimum and maximum latitude and longitude (see image below). For this reason, the *RasterLayer* object needs to be 'cropped' accordingly.

![](Pixel_centre_example_CGLS.png)



```{r}
if(extent(r)[1] < -180 & extent(r)[2] > 179.997){  # full image
  extnt_r <- extent(r)
  extnt_r[1] <- extent(r)[1] + (2 * (1 / 336)) # x-min
  extnt_r[2] <- extent(r)[2] - (1 * (1 / 336)) # x-max
  extnt_r[3] <- extent(r)[3] + (1 * (1 / 336))  # y-min
  extnt_r[4] <- extent(r)[4] - (2 * (1 / 336))  # y-max
  r <- crop(r, extnt_r)
}else{

}

```


If the user has subset part of the original 300m product, its new extention should match with the 1km product grid. Otherwise, the comparison or any other kind of calculations involving any of the 1km products cannot be made properly. The following vectors contain Long and Lat coordinates, respectively, of the 1km grid (edges of the cells):

```{r}

x_ext <- seq((-180 - ((1 / 112) / 2)), 180, (3 * (1 / 336)))
y_ext <- seq((80 + ((1 / 112) / 2)), - 60, - (3 * (1 / 336)))

```



When these checks and coorections are made, the process of resampling itself can go ahead using *aggregate()*.

```{r}
r300m_resampled1km_Aggr <- aggregate(r,
                                     fact = 3, # from 333m to 1km  
                                     fun = mean, 
                                     na.rm = TRUE, 
                                     filename = '')

```



Finally, a couple of plots in case the user wants to take a look at the resampled map.

```{r}
plot(r, main = 'Original map at 300m')
plot(r300m_resampled1km_Aggr, main = 'Resampled map to 1km')
```


