---
title: "Resample Tool With R"
output: html_notebook
---

# Reading in and preparing data 

When running the notebooks on VITOâ€™s servers, the user can follow the directions shown in 
https://nbviewer.jupyter.org/github/VITObelgium/notebook-samples/raw/master/datasets/probav/Reading%20PROBA-V%20using%20R.ipynb to find locations of PROBA-V products. Doing so, the data set (netCDF files) will be located and available in the VITO's servers.

Alternatively, when working locally, the R-user can choose to automatically download Copernicus land data (https://land.copernicus.eu/global/) using the functions found in https://github.com/cgls/Copernicus-Global-Land-Service-Data-Download-with-R. 

Once the data set is available, *raster* package functionality is used to prepare it for resampling. 

```{r}
library(raster)
library(knitr)
#setwd("/Users/xavi_rp/Documents/D6_LPD/ResampleTool_notebook")


# ndvi_files is a list of the available files (netCFD or Raster* objects)
ndvi_files <- list(paste0("/Users/xavi_rp/Documents/D6_LPD/NDVI_resample", "/ndvi300m_Cat.tif"))
r <- raster(ndvi_files[[1]])

```


The original netCDF file might contain flagged data corresponding to NoData (NA), etc, which needs to be dealt with. In the following table it can be seen the range of valid values, both DN and physical, for each product and data layer.

```{r echo = FALSE}
cutoff_method_df <- read.csv("Table_cutoff_and_resampleMethod.csv",
                             stringsAsFactors = FALSE,
                             header = TRUE)
cutoff_method_df <- as.data.frame(gsub("(\\[|\\])", "", as.matrix(cutoff_method_df)))
cutoff_method_df <- as.data.frame(gsub("(\\.\\.\\.)", "_", as.matrix(cutoff_method_df)))

cutoff_method_df$Valid.range.DN.from <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), "_"))[[1]]))
cutoff_method_df$Valid.range.DN.to <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), "_"))[[2]]))

cutoff_method_df$Valid.range.physical.from <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), "_"))[[1]]))
cutoff_method_df$Valid.range.physical.to <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), "_"))[[2]]))

cutoff_method_df <- cutoff_method_df[, c("Product","Data.layer.in.file",
                                         "Valid.range.DN.from", "Valid.range.DN.to",
                                         "Valid.range.physical.from", "Valid.range.physical.to",
                                         "Resample.method", "Additional.cutoff")]

#print(cutoff_method_df)
kable(cutoff_method_df[, 1:6], caption = "")

cutoff_method_df_ndvi_to <- cutoff_method_df[cutoff_method_df$Data.layer.in.file == "NDVI", c(4, 6)]
```


In case of the NDVI products and netCDF files, assigned values > `r as.character(cutoff_method_df_ndvi_to[1])` are flagged and need to be converted into NA. When netCDF files are read in as a *Raster*\* object and values transformed into real NDVI values, the cutoff for flagged cells is `r as.character(cutoff_method_df_ndvi_to[2])`. Therefore, all cells > `r as.character(cutoff_method_df_ndvi_to[2])` have to be set to NA.



```{r}
if(grepl("ndvi", ndvi_files[[1]], ignore.case = TRUE)){
  cutoff_flag <- as.numeric(cutoff_method_df_ndvi_to[2])
}else{
  print("Please define 'cutoff_flag' (cutoff value for flagged cells) for the Raster* object")
}

r[r > cutoff_flag] <- NA

```



# Resampling using the aggregation approach

There are several approaches to resample data to a coarser resolution. The area-based aggregation methods are based in grouping rectangular areas of cells of the finer resolution image to create a new map with larger cells. To do that, the function *aggregate()* of the package *raster* needs to know the factor of aggregation. In this case, the factor is 3 as it needs to go from 333m to 1km. In addition, *aggregate()* can perform the calculation using different functions. While the default is the average (*mean()*) it can work also with *modal()*, *max()* or *min()*. The following table recommends the best suited method for each product/layer.

```{r echo = FALSE}
kable(cutoff_method_df[, c(1:2, 7)], caption = "")

cutoff_method_df_ndvi_method <- cutoff_method_df[cutoff_method_df$Data.layer.in.file == "NDVI", 7]

```


As for the pixel coordinate definition for both the 300m and the 1km products, no proper aggregation of the finer resolution product can be performed at the minimum and maximum latitude and longitude (see image below). For this reason, the *RasterLayer* object needs to be 'cropped' accordingly.

![](Pixel_centre_example_CGLS.png)



```{r}
if(extent(r)[1] < -180 & extent(r)[2] > 179.997 &
   extent(r)[3] < -59.99554 & extent(r)[4] > 80){  # full image
  extnt_r <- extent(r)
  extnt_r[1] <- extent(r)[1] + (2 * (1 / 336)) # x-min
  extnt_r[2] <- extent(r)[2] - (1 * (1 / 336)) # x-max
  extnt_r[3] <- extent(r)[3] + (1 * (1 / 336))  # y-min
  extnt_r[4] <- extent(r)[4] - (2 * (1 / 336))  # y-max
  r <- crop(r, extnt_r)
}else{
  print("The image is not the full product; therefore extent needs to be checked")
}
```


If the user has subset part of the original 300m product, its new extent should match with the 1km product grid. Otherwise, the comparison or any other kind of calculations involving any of the 1km products cannot be made properly. So, on the one hand, if the user provides a 1km *Raster*\* object, the 300m product to be resampled will be geographically subset accordingly. On the other hand, if no 1km object is provided, the 300m product will be subset so that its extent matches with the closer grid coordinates (Lat/Long) of the 1km products.


```{r echo = TRUE}
#The following vectors contain Long and Lat coordinates, respectively, of the #1km grid (edges of the cells):
x_ext <- seq((-180 - ((1 / 112) / 2)), 180, (3 * (1 / 336)))
y_ext <- seq((80 + ((1 / 112) / 2)), - 60, - (3 * (1 / 336)))
```

```{r}
ndvi_files_1km <- list(paste0("/Users/xavi_rp/Documents/D6_LPD/NDVI_resample", "/ndvi1km_Cat.tif"))
r_1km <- raster(ndvi_files_1km[[1]])

if(exists("r_1km") & all(round(res(r_1km), 8) == 0.00892857) &
   extent(r_1km)[1] %in% x_ext & extent(r_1km)[2] %in% x_ext &
   extent(r_1km)[3] %in% y_ext & extent(r_1km)[4] %in% y_ext){ # r_1km matches with PROBA-V 1km products
  
  r <- crop(r, r_1km)
  
}else if(){      # r_1km exists but does not match with PROBA-V 1km products
  
  
}else{           # r_1km not provided
  
  
}
```


When these checks and coorections are made, the process of resampling itself can go ahead using *aggregate()*.

```{r}
r300m_resampled1km_Aggr <- aggregate(r,
                                     fact = 3, # from 333m to 1km  
                                     fun = mean, 
                                     na.rm = TRUE, 
                                     filename = '')

```



Finally, a couple of plots in case the user wants to take a look at the resampled map.

```{r}
plot(r, main = 'Original map at 300m')
plot(r300m_resampled1km_Aggr, main = 'Resampled map to 1km')
```


