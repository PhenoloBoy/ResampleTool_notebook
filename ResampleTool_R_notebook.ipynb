{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Resample Tool With R\"\n",
    "output: html_notebook\n",
    "author: Xavier Rotllan-Puig (xavier.rotllan.puig@aster-projects.cat) with support of Tim Jacobs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Tool\n",
    "\n",
    "This notebook shows how to resample PROBA-V products (i.e. NDVI, FAPAR...) from 333m resolution to 1km using R-based packages and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and preparing data \n",
    "\n",
    "When running this notebook on VITOâ€™s servers, the user can follow the directions shown in \n",
    "https://nbviewer.jupyter.org/github/VITObelgium/notebook-samples/raw/master/datasets/probav/Reading%20PROBA-V%20using%20R.ipynb to find locations of PROBA-V products and prepare them to be used. Doing so, the data set (netCDF files) will be located and available in the VITO's servers.\n",
    "\n",
    "Alternatively, when working locally, the R-user can choose to automatically download Copernicus land data (https://land.copernicus.eu/global/) using the functions found in https://github.com/cgls/Copernicus-Global-Land-Service-Data-Download-with-R. \n",
    "\n",
    "Once the data set is available, *raster* package functionality is used to prepare it for resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "library(raster)\n",
    "#library(knitr)\n",
    "if(require(knitr) == FALSE){install.packages(\"knitr\", repos = \"https://cloud.r-project.org\"); library(knitr)} else {library(knitr)}\n",
    "\n",
    "# ndvi_files is a list of the available files (netCFD or Raster* objects)\n",
    "ndvi_files <- list(paste0(getwd(), \"/ndvi300m_Cat_kk.tif\"))\n",
    "r <- raster(ndvi_files[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original netCDF file might contain flagged data corresponding to NoData (NA), etc, which needs to be dealt with. In the following table it can be seen the range of valid values, both DN and physical, for each product and data layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "cutoff_method_df <- read.csv(paste0(getwd(), \"/Table_cutoff_and_resampleMethod.csv\"),\n",
    "                             stringsAsFactors = FALSE,\n",
    "                             header = TRUE)\n",
    "cutoff_method_df <- as.data.frame(gsub(\"(\\\\[|\\\\])\", \"\", as.matrix(cutoff_method_df)))\n",
    "cutoff_method_df <- as.data.frame(gsub(\"(\\\\.\\\\.\\\\.)\", \"_\", as.matrix(cutoff_method_df)))\n",
    "\n",
    "cutoff_method_df$Valid.range.DN.min <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), \"_\"))[[1]]))\n",
    "cutoff_method_df$Valid.range.DN.max <- unlist(lapply(cutoff_method_df$Valid.range.DN, function(x) unlist(strsplit(as.character(x), \"_\"))[[2]]))\n",
    "\n",
    "cutoff_method_df$Valid.range.physical.min <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), \"_\"))[[1]]))\n",
    "cutoff_method_df$Valid.range.physical.max <- unlist(lapply(cutoff_method_df$Valid.range.physical, function(x) unlist(strsplit(as.character(x), \"_\"))[[2]]))\n",
    "\n",
    "cutoff_method_df <- cutoff_method_df[, c(\"Product\",\"Data.layer.in.file\",\n",
    "                                         \"Valid.range.DN.min\", \"Valid.range.DN.max\",\n",
    "                                         \"Valid.range.physical.min\", \"Valid.range.physical.max\",\n",
    "                                         \"Resample.method\", \"Additional.cutoff\")]\n",
    "\n",
    "kable(cutoff_method_df[, 1:6], caption = \"\")\n",
    "\n",
    "cutoff_method_df_ndvi_max <- cutoff_method_df[cutoff_method_df$Data.layer.in.file == \"NDVI\", c(4, 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in case of the NDVI products and netCDF files, assigned values > 250 are flagged and need to be converted into NA. When netCDF files are read in as a *Raster*\\* object and values transformed into real NDVI values, the cutoff for flagged cells is 0.92. Therefore, all cells > 0.92 have to be set to NA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cutoff_flag <- 0.92\n",
    "\n",
    "r[r > cutoff_flag] <- NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling using the aggregation approach\n",
    "\n",
    "There are several approaches to resample data to a coarser resolution. The area-based aggregation methods are based in grouping rectangular areas of cells of the finer resolution image to create a new map with larger cells. To do that, the function *aggregate()* of the package *raster* needs to know the factor of aggregation. In this case, the factor is 3 as it needs to go from 333m to 1km. In addition, *aggregate()* can perform the calculation using different functions. While the default is the average (*mean()*) it can work also with *modal()*, *max()*, *min()* or *ad hoc* functions (e.g. *closest_to_mean()*, see below). The following table recommends the best suited method for each product/layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "kable(cutoff_method_df[, c(1:2, 7)], caption = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the pixel coordinate definition for both the 300m and the 1km products, no proper aggregation of the finer resolution product can be performed at the minimum and maximum latitude and longitude (see image below). For this reason, the 300m *RasterLayer* object needs to be adjusted accordingly.\n",
    "\n",
    "![](Pixel_centre_example_CGLS.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if(extent(r)[1] < -180 & extent(r)[2] > 179.997 &\n",
    "   extent(r)[3] < -59.99554 & extent(r)[4] > 80){  # checking for full product (image)\n",
    "  extnt_r <- extent(r)\n",
    "  extnt_r[1] <- extent(r)[1] + (2 * (1 / 336)) # x-min\n",
    "  extnt_r[2] <- extent(r)[2] - (1 * (1 / 336)) # x-max\n",
    "  extnt_r[3] <- extent(r)[3] + (1 * (1 / 336))  # y-min\n",
    "  extnt_r[4] <- extent(r)[4] - (2 * (1 / 336))  # y-max\n",
    "  r <- crop(r, extnt_r)\n",
    "}else{\n",
    "  print(\"The image is not the full product; therefore, extent needs to be checked\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to use a subset of the original 300m product, its new extent should match with the 1km product grid. Otherwise, the comparison or any other kind of calculations involving any of the 1km PROVA-B products cannot be made properly. \n",
    "\n",
    "So, at this point, the user has two alternative options. On the one hand, the user can provide a 1km *Raster*\\* object based on a subset of any PROVA-B product at 1km resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ndvi_files_1km <- list(paste0(\"/Users/xavi_rp/Documents/D6_LPD/NDVI_resample\", \"/ndvi1km_Cat.tif\"))\n",
    "r_1km <- raster(ndvi_files_1km[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if no 1km object is provided, a vector with coordinates can be used for subsetting the 300m product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "coords4subset <- c(0, 4, 40, 43) # a vector with Long/Lat decimal degrees in the form c(Xmin, Xmax, Ymin, Ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with both options the extent provided might experience slight changes given that the new extent of the 300m product has to match exactly with the grid coordinates of the 1km products.\n",
    "\n",
    "Then, the 300m product to be resampled can be geographically subset accordingly to the chosen option and the final extent adjusted if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": true
   },
   "outputs": [],
   "source": [
    "#The following vectors contain Long and Lat coordinates, respectively, of the 1km grid (edges of the cells):\n",
    "x_ext <- seq((-180 - ((1 / 112) / 2)), 180, (1/112))\n",
    "y_ext <- seq((80 + ((1 / 112) / 2)), - 60, - (1/112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if(exists(\"r_1km\") & all(round(res(r_1km), 7) == round(0.00892857, 7)) &\n",
    "   round(extent(r_1km)[1], 7) %in% round(x_ext, 7) & \n",
    "   round(extent(r_1km)[2], 7) %in% round(x_ext, 7) &\n",
    "   round(extent(r_1km)[3], 7) %in% round(y_ext, 7) &\n",
    "   round(extent(r_1km)[4], 7) %in% round(y_ext, 7)){ # r_1km matches with PROBA-V 1km products\n",
    "  \n",
    "  r <- crop(r, r_1km)\n",
    "  \n",
    "}else if(exists(\"r_1km\") & all(round(res(r_1km), 7) == round(0.00892857, 7)) &\n",
    "   !all(round(extent(r_1km)[1], 7) %in% round(x_ext, 7) & \n",
    "   round(extent(r_1km)[2], 7) %in% round(x_ext, 7) &\n",
    "   round(extent(r_1km)[3], 7) %in% round(y_ext, 7) &\n",
    "   round(extent(r_1km)[4], 7) %in% round(y_ext, 7))){  # r_1km exists but does not match with PROBA-V 1km products\n",
    "  \n",
    "  stop(\"Please provide a 1km object adjusted to 1km PROBA-V products\")\n",
    "\n",
    "}else if (!exists(\"r_1km\") & exists(\"coords4subset\") &\n",
    "          length(coords4subset) == 4 &\n",
    "          all(coords4subset >= -180) &\n",
    "          all(coords4subset <= 180)){  # r_1km not provided, but coordinates to subset from\n",
    "  \n",
    "  coords4subset <- extent(coords4subset)\n",
    "  r <- crop(r, coords4subset)\n",
    "  \n",
    "}else{\n",
    "  stop(\"Please provide either a 1km PROBA-V product or a set of coordinates to cut from\")\n",
    "}\n",
    "\n",
    "\n",
    "## Adjusting extent\n",
    "extnt <- extent(r)\n",
    "  \n",
    "repeat{# adjusting columns (Lon) at left\n",
    "  if (round(extnt[1], 7) %in% round(x_ext, 7)) break\n",
    "  cat(\"\\r\", \"Please note that 300m object X-min does not overlap 1km object X-min. Keep it in mind for further analysis\")\n",
    "  extnt[1] <- extnt[1] + (1/336)\n",
    "}\n",
    "\n",
    "repeat{ # adjusting columns (Lon) at right\n",
    "  if(round(extnt[2], 7) %in% round(x_ext, 7)) break\n",
    "  cat(\"\\r\", \"Please note that 300m object X-max does not overlap 1km object X-max. Keep it in mind for further analysis\")\n",
    "  extnt[2] <- extnt[2] - (1/336)\n",
    "}\n",
    "\n",
    "repeat{# adjusting rows (Lat) at top\n",
    "  if (round(extnt[4], 7) %in% round(y_ext, 7)) break\n",
    "  cat(\"\\r\", \"Please note that 300m object Y-max does not overlap 1km object Y-max. Keep it in mind for further analysis\")\n",
    "  extnt[4] <- extnt[4] - (1/336)\n",
    "}\n",
    "\n",
    "repeat{ # adjusting rows (Lat) at bottom\n",
    "  if(round(extnt[3], 7) %in% round(y_ext, 7)) break\n",
    "  cat(\"\\r\", \"Please note that 300m object Y-min does not overlap 1km object Y-min. Keep it in mind for further analysis\")\n",
    "  extnt[3] <- extnt[3] + (1/336)\n",
    "}\n",
    "\n",
    "r <- crop(r, extnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When these checks and coorections are made, the process of resampling itself can go ahead using *aggregate()*. The resample method can be assigned at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#aggr_method <- \"median\"\n",
    "#aggr_method <- \"modal\"\n",
    "#aggr_method <- \"closest_to_mean\"\n",
    "\n",
    "closest_to_mean <- function(x, ...){\n",
    "  dts <- list(...)\n",
    "  if(is.null(dts$na_rm)) dts$na_rm <- TRUE\n",
    "  x_mean <- mean(x, na.rm = dts$na_rm)\n",
    "  closest2avrge <- x[order(abs(x - x_mean))][1]\n",
    "  return(closest2avrge)\n",
    "\n",
    "}\n",
    "\n",
    "aggr_method <- \"mean\"\n",
    "r300m_resampled1km_Aggr <- aggregate(r,\n",
    "                                     fact = 3, # from 333m to 1km  \n",
    "                                     fun = aggr_method, \n",
    "                                     na.rm = TRUE, \n",
    "                                     filename = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a couple of plots in case the user wants to take a look at the resampled map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(r, main = 'Original map at 300m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plot(r300m_resampled1km_Aggr, main = 'Resampled map to 1km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "echo,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
